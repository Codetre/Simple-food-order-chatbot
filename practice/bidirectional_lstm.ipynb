{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from random import random\n",
    "from typing import Tuple\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from seqeval.metrics import f1_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 3344151048611754872\n",
       " xla_global_id: -1]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 양방향 LSTM(Bi-directional LSTM)\n",
    "LSTM은 시퀀스 내 현재 시점을 오로지 이전 시점의 정보들로만 학습하고 추론한다는 한계가 있다.\n",
    "이 문제를 해결코자 시퀀스 현재 시점 전후를 모두 읽어들이도록 확장한 LSTM이 양방향 LSTM이다.\n",
    "간단하게 h_t = f(forward_lstm, backward_lstm) 정도로 표현할 수 있다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_sequence(length: int) -> Tuple:\n",
    "    x = np.array([random() for _ in range(length)])\n",
    "    limit = length / 4.0\n",
    "    y = np.array([0 if elem < limit else 1 for elem in np.cumsum(x)])\n",
    "\n",
    "    # 양방향 LSTM 레이어에서 요구하는 형태(n_dim = 3)로 전처리.\n",
    "    x = x.reshape(1, length, 1)\n",
    "    y = y.reshape(1, length, 1)\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_units = 20\n",
    "n_timestpes = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"loss\",\n",
    "    patience=5,\n",
    "    mode=\"auto\")\n",
    "\n",
    "input_layer = keras.layers.Input(shape=(n_timestpes, 1))\n",
    "bi_lstm_layer_fn = keras.layers.Bidirectional(\n",
    "    keras.layers.LSTM(units=n_units,\n",
    "                      return_sequences=True))(input_layer)\n",
    "dense_layer_fn = keras.layers.TimeDistributed(\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\"))(bi_lstm_layer_fn)\n",
    "bi_lstm_model = keras.Model(inputs=input_layer, outputs=dense_layer_fn)\n",
    "\n",
    "bi_lstm_model.compile(loss=\"binary_crossentropy\",\n",
    "                      optimizer=\"adam\",\n",
    "                      metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset_x, dataset_y = get_sequence(n_timestpes)\n",
    "test_x, test_y = get_sequence(n_timestpes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6970 - accuracy: 0.4000\n",
      "Epoch 2/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6942 - accuracy: 0.4200\n",
      "Epoch 3/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6916 - accuracy: 0.5700\n",
      "Epoch 4/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6892 - accuracy: 0.6500\n",
      "Epoch 5/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6869 - accuracy: 0.6300\n",
      "Epoch 6/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6846 - accuracy: 0.6200\n",
      "Epoch 7/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6825 - accuracy: 0.6000\n",
      "Epoch 8/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6805 - accuracy: 0.6000\n",
      "Epoch 9/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6786 - accuracy: 0.6000\n",
      "Epoch 10/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6768 - accuracy: 0.6000\n",
      "Epoch 11/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6750 - accuracy: 0.6000\n",
      "Epoch 12/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6733 - accuracy: 0.6000\n",
      "Epoch 13/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6717 - accuracy: 0.6000\n",
      "Epoch 14/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6701 - accuracy: 0.6000\n",
      "Epoch 15/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6685 - accuracy: 0.6000\n",
      "Epoch 16/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6670 - accuracy: 0.6000\n",
      "Epoch 17/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6654 - accuracy: 0.6000\n",
      "Epoch 18/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6638 - accuracy: 0.6000\n",
      "Epoch 19/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6622 - accuracy: 0.6000\n",
      "Epoch 20/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6605 - accuracy: 0.6000\n",
      "Epoch 21/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6588 - accuracy: 0.6000\n",
      "Epoch 22/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6570 - accuracy: 0.6000\n",
      "Epoch 23/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6551 - accuracy: 0.6000\n",
      "Epoch 24/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6530 - accuracy: 0.6000\n",
      "Epoch 25/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6509 - accuracy: 0.6000\n",
      "Epoch 26/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6486 - accuracy: 0.6000\n",
      "Epoch 27/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6461 - accuracy: 0.6000\n",
      "Epoch 28/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6435 - accuracy: 0.6000\n",
      "Epoch 29/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6407 - accuracy: 0.6000\n",
      "Epoch 30/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6378 - accuracy: 0.6000\n",
      "Epoch 31/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6347 - accuracy: 0.6000\n",
      "Epoch 32/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6313 - accuracy: 0.6000\n",
      "Epoch 33/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6278 - accuracy: 0.6000\n",
      "Epoch 34/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6241 - accuracy: 0.6000\n",
      "Epoch 35/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6202 - accuracy: 0.6100\n",
      "Epoch 36/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6160 - accuracy: 0.6100\n",
      "Epoch 37/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6115 - accuracy: 0.6100\n",
      "Epoch 38/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6066 - accuracy: 0.6200\n",
      "Epoch 39/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6011 - accuracy: 0.6200\n",
      "Epoch 40/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5951 - accuracy: 0.6300\n",
      "Epoch 41/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5883 - accuracy: 0.6300\n",
      "Epoch 42/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5805 - accuracy: 0.6300\n",
      "Epoch 43/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5717 - accuracy: 0.6400\n",
      "Epoch 44/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5616 - accuracy: 0.6400\n",
      "Epoch 45/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5501 - accuracy: 0.6500\n",
      "Epoch 46/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5369 - accuracy: 0.6700\n",
      "Epoch 47/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5221 - accuracy: 0.7000\n",
      "Epoch 48/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5055 - accuracy: 0.7200\n",
      "Epoch 49/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4876 - accuracy: 0.7400\n",
      "Epoch 50/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4690 - accuracy: 0.7600\n",
      "Epoch 51/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4506 - accuracy: 0.8500\n",
      "Epoch 52/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4330 - accuracy: 0.8800\n",
      "Epoch 53/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4155 - accuracy: 0.9400\n",
      "Epoch 54/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3967 - accuracy: 0.9600\n",
      "Epoch 55/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3770 - accuracy: 0.9700\n",
      "Epoch 56/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3588 - accuracy: 0.9600\n",
      "Epoch 57/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3438 - accuracy: 0.9500\n",
      "Epoch 58/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3304 - accuracy: 0.9500\n",
      "Epoch 59/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3163 - accuracy: 0.9700\n",
      "Epoch 60/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3037 - accuracy: 1.0000\n",
      "Epoch 61/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2952 - accuracy: 0.9900\n",
      "Epoch 62/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2825 - accuracy: 1.0000\n",
      "Epoch 63/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2745 - accuracy: 0.9800\n",
      "Epoch 64/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2653 - accuracy: 0.9800\n",
      "Epoch 65/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2571 - accuracy: 0.9900\n",
      "Epoch 66/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2489 - accuracy: 0.9900\n",
      "Epoch 67/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2430 - accuracy: 0.9800\n",
      "Epoch 68/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2340 - accuracy: 1.0000\n",
      "Epoch 69/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2318 - accuracy: 0.9800\n",
      "Epoch 70/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2261 - accuracy: 0.9800\n",
      "Epoch 71/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2168 - accuracy: 0.9900\n",
      "Epoch 72/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2203 - accuracy: 0.9700\n",
      "Epoch 73/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2084 - accuracy: 0.9800\n",
      "Epoch 74/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2065 - accuracy: 0.9800\n",
      "Epoch 75/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1967 - accuracy: 0.9900\n",
      "Epoch 76/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1931 - accuracy: 0.9900\n",
      "Epoch 77/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1908 - accuracy: 0.9800\n",
      "Epoch 78/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1827 - accuracy: 0.9900\n",
      "Epoch 79/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1840 - accuracy: 0.9800\n",
      "Epoch 80/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1716 - accuracy: 1.0000\n",
      "Epoch 81/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1717 - accuracy: 0.9800\n",
      "Epoch 82/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1628 - accuracy: 0.9900\n",
      "Epoch 83/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1609 - accuracy: 0.9900\n",
      "Epoch 84/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1568 - accuracy: 0.9900\n",
      "Epoch 85/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1496 - accuracy: 0.9900\n",
      "Epoch 86/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1495 - accuracy: 0.9800\n",
      "Epoch 87/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1398 - accuracy: 0.9900\n",
      "Epoch 88/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1371 - accuracy: 0.9900\n",
      "Epoch 89/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1318 - accuracy: 0.9900\n",
      "Epoch 90/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1249 - accuracy: 1.0000\n",
      "Epoch 91/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1222 - accuracy: 0.9900\n",
      "Epoch 92/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1141 - accuracy: 1.0000\n",
      "Epoch 93/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1096 - accuracy: 0.9900\n",
      "Epoch 94/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1052 - accuracy: 0.9900\n",
      "Epoch 95/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0982 - accuracy: 1.0000\n",
      "Epoch 96/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0955 - accuracy: 0.9900\n",
      "Epoch 97/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0912 - accuracy: 0.9900\n",
      "Epoch 98/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0852 - accuracy: 1.0000\n",
      "Epoch 99/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0838 - accuracy: 0.9900\n",
      "Epoch 100/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0811 - accuracy: 0.9900\n",
      "Epoch 101/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0754 - accuracy: 1.0000\n",
      "Epoch 102/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0735 - accuracy: 0.9900\n",
      "Epoch 103/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0726 - accuracy: 0.9900\n",
      "Epoch 104/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0681 - accuracy: 1.0000\n",
      "Epoch 105/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0652 - accuracy: 1.0000\n",
      "Epoch 106/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0647 - accuracy: 0.9900\n",
      "Epoch 107/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0640 - accuracy: 0.9900\n",
      "Epoch 108/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0614 - accuracy: 0.9900\n",
      "Epoch 109/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0578 - accuracy: 1.0000\n",
      "Epoch 110/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0569 - accuracy: 1.0000\n",
      "Epoch 111/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0581 - accuracy: 0.9900\n",
      "Epoch 112/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0572 - accuracy: 0.9900\n",
      "Epoch 113/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0541 - accuracy: 0.9900\n",
      "Epoch 114/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0510 - accuracy: 1.0000\n",
      "Epoch 115/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0509 - accuracy: 0.9900\n",
      "Epoch 116/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0519 - accuracy: 0.9900\n",
      "Epoch 117/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0502 - accuracy: 0.9900\n",
      "Epoch 118/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0474 - accuracy: 1.0000\n",
      "Epoch 119/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0458 - accuracy: 1.0000\n",
      "Epoch 120/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0461 - accuracy: 1.0000\n",
      "Epoch 121/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0466 - accuracy: 0.9900\n",
      "Epoch 122/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0453 - accuracy: 0.9900\n",
      "Epoch 123/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0433 - accuracy: 1.0000\n",
      "Epoch 124/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0419 - accuracy: 1.0000\n",
      "Epoch 125/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0417 - accuracy: 1.0000\n",
      "Epoch 126/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0422 - accuracy: 0.9900\n",
      "Epoch 127/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0425 - accuracy: 0.9900\n",
      "Epoch 128/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0424 - accuracy: 0.9900\n",
      "Epoch 129/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0405 - accuracy: 0.9900\n",
      "Epoch 130/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0388 - accuracy: 1.0000\n",
      "Epoch 131/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0378 - accuracy: 1.0000\n",
      "Epoch 132/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0378 - accuracy: 1.0000\n",
      "Epoch 133/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0385 - accuracy: 0.9900\n",
      "Epoch 134/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0393 - accuracy: 0.9900\n",
      "Epoch 135/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0401 - accuracy: 0.9900\n",
      "Epoch 136/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0383 - accuracy: 0.9900\n",
      "Epoch 137/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0362 - accuracy: 1.0000\n",
      "Epoch 138/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0347 - accuracy: 1.0000\n",
      "Epoch 139/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0348 - accuracy: 1.0000\n",
      "Epoch 140/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0359 - accuracy: 0.9900\n",
      "Epoch 141/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0368 - accuracy: 0.9900\n",
      "Epoch 142/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0373 - accuracy: 0.9900\n",
      "Epoch 143/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0351 - accuracy: 0.9900\n"
     ]
    }
   ],
   "source": [
    "history = bi_lstm_model.fit(dataset_x, dataset_y, epochs=1000, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_y = bi_lstm_model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.64\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.05  # 차이가 이 값 미만이면 맞춘 걸로 인정.\n",
    "ans = np.abs(pred_y - test_y) < threshold\n",
    "acc = np.sum(ans) / n_timestpes\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 개체명 인식(NER: Named Entity Recognition)\n",
    "\"오늘 먹은 것은 제육볶음이다.\"란 문장이 있다고 하면 여기서 \"오늘\"은 \"날짜\", \"제육볶음\"은 \"음식\"이란\n",
    "범주로 파악할 수 있다. 여기서 \"날짜\", \"음식\" 등 범주나 유형 등을 '개체명'이라고 부른다. 텍스트 내에서\n",
    "단어의 개체명을 파악하는 일을 '개체명 인식'이라고 부른다.\n",
    "\n",
    "텍스트 내 단어에 개체명을 붙이기 위한 표기법으로 'BIO(beginning, Inside, Outside) 표기법'이 있다.\n",
    "B는 개체명이 시작하는 단어에, I는 B 태깅된 단어 뒤에서 그 개체명에 속하는 단어에, O는 아무 것도 아닌\n",
    "단어에 붙이는 태그다.\n",
    "\"'도미니크 공화국'은 카리브 해의 히스파니올라 섬 동쪽 약 5/8을 차지하고 있는 나라다(나무위키).\"는\n",
    "도미니크(B-country), 공화국(I-country), 카리브(B-sea), 해(I-sea), 히스파니올라(B-island),\n",
    "섬(I-island) 등으로 태깅할 수 있다('B-country'등은 임의로 붙인 것).\n",
    "\n",
    "여기 사용된 데이터셋은 [KoreanNERCorpus](https://github.com/machinereading/KoreanNERCorpus)에서 받음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 데이터 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_file(file):\n",
    "    \"\"\"데이터 파일을 파싱\n",
    "\n",
    "    파일은\n",
    "        1. 세미콜론으로 시작하는 원본 문장,\n",
    "        2. 그 다음엔 달러 기호로 시작하는 BIO 태깅된 문장,\n",
    "        3. 그 이후부터 다음 원본 문장 전까지는 각 토큰의 피처들의 나열(ID, token, POS, BIO)\n",
    "    이렇게 세 종류의 줄로 이루어져 있다.\n",
    "\n",
    "    :param file: BIO 토큰 정보를 가진 파일.\n",
    "    :return: 각 줄의 모든 피처를 열거한 리스트: [feats_sentence1, feats_sentence2, ...]\n",
    "    \"\"\"\n",
    "\n",
    "    # 어떤 라인인지 파악하기 위한 조건\n",
    "    def is_original_line(cur_i, lines):\n",
    "        if cur_i >= len(lines) - 1:\n",
    "            return False\n",
    "        else:\n",
    "            cur_line, next_line = lines[cur_i], lines[cur_i + 1]\n",
    "            cur_first_char = cur_line[0]\n",
    "            next_first_char = next_line[0]\n",
    "            return cur_first_char == \";\" and next_first_char == '$'\n",
    "\n",
    "    def is_ner_processed_line(cur_i, lines):\n",
    "        cur_line = lines[cur_i]\n",
    "        first_char = cur_line[0]\n",
    "        return first_char == \"$\"\n",
    "\n",
    "    def is_end_of_datapoint(line):\n",
    "        first_char = line[0]\n",
    "        return first_char == \"\\n\"\n",
    "\n",
    "    features_all_lines = []  # 파일 내 모든 문장의 토큰 피처들\n",
    "    with open(file, 'r', encoding=\"utf-8\") as fin:\n",
    "        lines = fin.readlines()\n",
    "\n",
    "        for i, line in enumerate(lines):\n",
    "            if is_original_line(i, lines):\n",
    "                features_a_line = []\n",
    "            elif is_ner_processed_line(i, lines):\n",
    "                continue\n",
    "            elif is_end_of_datapoint(line):\n",
    "                features_all_lines.append(features_a_line)\n",
    "            else:\n",
    "                features_a_line.append(line.split())\n",
    "    return features_all_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus = read_file(\"data/corpus/korean_ner/train.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[[['1', '한편', 'NNG', 'O'],\n  ['1', ',', 'SP', 'O'],\n  ['2', 'AFC', 'SL', 'O'],\n  ['2', '챔피언스', 'NNG', 'O'],\n  ['2', '리그', 'NNG', 'O'],\n  ['3', 'E', 'SL', 'B_OG'],\n  ['3', '조', 'NNG', 'I'],\n  ['3', '에', 'JKB', 'O'],\n  ['4', '속하', 'VV', 'O'],\n  ['4', 'ㄴ', 'ETM', 'O'],\n  ['5', '포항', 'NNP', 'O'],\n  ['6', '역시', 'MAJ', 'O'],\n  ['7', '대회', 'NNG', 'O'],\n  ['8', '8강', 'NNG', 'O'],\n  ['9', '진출', 'NNG', 'O'],\n  ['9', '이', 'JKS', 'O'],\n  ['10', '불투명', 'NNG', 'O'],\n  ['10', '하', 'VV', 'O'],\n  ['10', '다', 'EC', 'O'],\n  ['11', '.', 'SF', 'O']],\n [['1', '2003', 'SN', 'B_DT'],\n  ['1', '년', 'NNB', 'I'],\n  ['2', '6', 'SN', 'I'],\n  ['2', '월', 'NNB', 'I'],\n  ['3', '14', 'SN', 'I'],\n  ['3', '일', 'NNB', 'I'],\n  ['4', '사직', 'NNG', 'O'],\n  ['5', '두산', 'NNP', 'O'],\n  ['5', '전', 'NNG', 'O'],\n  ['6', '이후', 'NNG', 'O'],\n  ['7', '박명환', 'NNP', 'B_PS'],\n  ['7', '에게', 'JKB', 'O'],\n  ['8', '당하', 'VV', 'O'],\n  ['8', '았', 'EP', 'O'],\n  ['8', '던', 'ETM', 'O'],\n  ['9', '10', 'SN', 'O'],\n  ['9', '연패', 'NNG', 'O'],\n  ['10', '사슬', 'NNG', 'O'],\n  ['10', '을', 'JKO', 'O'],\n  ['11', '거의', 'MAG', 'O'],\n  ['12', '5', 'SN', 'B_DT'],\n  ['12', '년', 'NNB', 'I'],\n  ['13', '만', 'NNB', 'O'],\n  ['13', '에', 'JKB', 'O'],\n  ['14', '끊', 'VV', 'O'],\n  ['14', '는', 'ETM', 'O'],\n  ['15', '의미', 'NNG', 'O'],\n  ['15', '있', 'VV', 'O'],\n  ['15', '는', 'ETM', 'O'],\n  ['16', '승리', 'NNG', 'O'],\n  ['16', '이', 'VCP', 'O'],\n  ['16', '었', 'EP', 'O'],\n  ['16', '다', 'EC', 'O'],\n  ['17', '.', 'SF', 'O']],\n [['1', 'AP', 'SL', 'B_OG'],\n  ['1', '통신', 'NNG', 'I'],\n  ['1', '은', 'JX', 'O'],\n  ['2', '8', 'SN', 'B_DT'],\n  ['2', '일', 'NNB', 'I'],\n  ['2', '(', 'SS', 'O'],\n  ['2', '이하', 'NNG', 'O'],\n  ['3', '한국', 'NNP', 'B_LC'],\n  ['3', '시간', 'NNG', 'O'],\n  ['3', ')', 'SS', 'O'],\n  ['4', '올라주원', 'NNP', 'B_PS'],\n  ['4', ',', 'SP', 'O'],\n  ['5', '유잉', 'NNP', 'B_PS'],\n  ['5', '을', 'JKO', 'O'],\n  ['6', '비롯', 'XR', 'O'],\n  ['6', '하', 'XSV', 'O'],\n  ['6', '아', 'EC', 'O'],\n  ['7', '애드리언', 'NNP', 'B_PS'],\n  ['8', '댄틀리', 'NNP', 'I'],\n  ['8', ',', 'SP', 'O'],\n  ['9', '팻', 'NNP', 'B_PS'],\n  ['10', '라일리', 'NNP', 'I'],\n  ['11', '감독', 'NNG', 'O'],\n  ['11', ',', 'SP', 'O'],\n  ['12', '캐시', 'NNG', 'B_PS'],\n  ['13', '러시', 'NNG', 'I'],\n  ['14', '감독', 'NNG', 'O'],\n  ['14', ',', 'SP', 'O'],\n  ['15', 'TV', 'SL', 'O'],\n  ['16', '해설가', 'NNG', 'O'],\n  ['17', '딕', 'NNP', 'B_PS'],\n  ['18', '바이텔', 'NNP', 'I'],\n  ['18', ',', 'SP', 'O'],\n  ['19', '디트로이트', 'NNP', 'B_OG'],\n  ['20', '피스톤스', 'NNP', 'I'],\n  ['20', '의', 'JKG', 'O'],\n  ['21', '구단주', 'NNG', 'O'],\n  ['22', '윌리엄', 'NNP', 'B_PS'],\n  ['23', '데이비드슨', 'NNP', 'I'],\n  ['24', '등', 'NNB', 'O'],\n  ['24', '이', 'JKS', 'O'],\n  ['25', '2008', 'SN', 'B_DT'],\n  ['26', '명예', 'NNG', 'O'],\n  ['26', '의', 'JKG', 'O'],\n  ['27', '전당', 'NNG', 'O'],\n  ['28', '헌액', 'NNG', 'O'],\n  ['28', '자', 'NNG', 'O'],\n  ['28', '로', 'JKB', 'O'],\n  ['29', '결정', 'NNG', 'O'],\n  ['29', '되', 'XSV', 'O'],\n  ['29', '었', 'EP', 'O'],\n  ['29', '다고', 'EC', 'O'],\n  ['30', '보', 'VV', 'O'],\n  ['30', '아도', 'EC', 'O'],\n  ['30', '하', 'VX', 'O'],\n  ['30', '았', 'EP', 'O'],\n  ['30', '다', 'EC', 'O'],\n  ['31', '.', 'SF', 'O']],\n [['1', '(', 'SS', 'O'],\n  ['1', '개막', 'NNG', 'O'],\n  ['2', '6', 'SN', 'O'],\n  ['2', '연패', 'NNG', 'O'],\n  ['2', ')', 'SS', 'O'],\n  ['2', '\"', 'SS', 'O'],\n  ['2', '짐', 'NNP', 'B_PS'],\n  ['3', '릴랜드', 'NNP', 'I'],\n  ['4', '디트로이트', 'NNP', 'B_OG'],\n  ['5', '감독', 'NNG', 'O'],\n  ['5', '은', 'JX', 'O'],\n  ['6', '메이저리그', 'NNG', 'B_OG'],\n  ['6', '에서', 'JKB', 'O'],\n  ['7', '손꼽히', 'VV', 'O'],\n  ['7', '는', 'ETM', 'O'],\n  ['8', '명장', 'NNG', 'O'],\n  ['8', '이', 'VCP', 'O'],\n  ['8', '면서', 'EC', 'O'],\n  ['9', '덕장', 'NNG', 'O'],\n  ['9', '이', 'VCP', 'O'],\n  ['9', '다', 'EC', 'O'],\n  ['10', '.', 'SF', 'O']],\n [['1', '역시', 'MAJ', 'O'],\n  ['2', '새로', 'MAG', 'O'],\n  ['3', '데려오', 'VV', 'O'],\n  ['3', 'ㄴ', 'ETM', 'O'],\n  ['4', '돈트렐', 'NNP', 'B_PS'],\n  ['5', '윌리스', 'NNP', 'I'],\n  ['5', '는', 'JX', 'O'],\n  ['6', '6', 'SN', 'B_DT'],\n  ['6', '일', 'NNB', 'I'],\n  ['7', '경기', 'NNG', 'O'],\n  ['7', '에서', 'JKB', 'O'],\n  ['8', '삼진', 'NNG', 'O'],\n  ['8', '을', 'JKO', 'O'],\n  ['9', '하나', 'NR', 'O'],\n  ['9', '도', 'JX', 'O'],\n  ['10', '잡', 'VV', 'O'],\n  ['10', '지', 'EC', 'O'],\n  ['11', '않', 'VX', 'O'],\n  ['11', '고', 'EC', 'O'],\n  ['12', '볼넷', 'NNG', 'O'],\n  ['13', '7', 'SN', 'O'],\n  ['13', '개', 'NNB', 'O'],\n  ['13', '를', 'JKO', 'O'],\n  ['14', '내주', 'VV', 'O'],\n  ['14', '는', 'ETM', 'O'],\n  ['15', '엽기', 'NNG', 'O'],\n  ['16', '피칭', 'NNG', 'O'],\n  ['16', '을', 'JKO', 'O'],\n  ['17', '하', 'VV', 'O'],\n  ['17', '었', 'EP', 'O'],\n  ['17', '다', 'EC', 'O'],\n  ['18', '.', 'SF', 'O']]]"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 문장별로 토큰(입력)과 BIO 태그(정답)를 따로 수집한다.\n",
    "tokens_all_sentences, bios_all_sentences = [], []\n",
    "for tags_a_sentence in corpus:\n",
    "    tokens_a_sentence, bios_a_sentence = [], []\n",
    "\n",
    "    for features in tags_a_sentence:\n",
    "        token, bio = features[1], features[3]\n",
    "        tokens_a_sentence.append(token)\n",
    "        bios_a_sentence.append(bio)\n",
    "\n",
    "    tokens_all_sentences.append(tokens_a_sentence)\n",
    "    bios_all_sentences.append(bios_a_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "첫번째 문장의 토큰-BIO 태그 샘플들 10개:\n",
      "한편 O\n",
      ", O\n",
      "AFC O\n",
      "챔피언스 O\n",
      "리그 O\n",
      "E B_OG\n",
      "조 I\n",
      "에 O\n",
      "속하 O\n",
      "ㄴ O\n"
     ]
    }
   ],
   "source": [
    "sentence_id = 0\n",
    "\n",
    "tokens = tokens_all_sentences[sentence_id]\n",
    "bios = bios_all_sentences[sentence_id]\n",
    "n_samples = 10\n",
    "print(f\"첫번째 문장의 토큰-BIO 태그 샘플들 {n_samples}개:\")\n",
    "for t, b in zip(tokens[:n_samples], bios[:n_samples]):\n",
    "    print(t, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num('O')/num('BIO') = 0.8567379285838244\n"
     ]
    }
   ],
   "source": [
    "# 결과를 보면 BIO 중 O가 대다수인 편향이 있음을 알 수 있다. 따라서 학습된 모델은 정확도보다\n",
    "# F-1 점수로 검증함이 더 공정하다.\n",
    "def rate_category(cat, data):\n",
    "    \"\"\"\n",
    "\n",
    "    :param cat: {BIO} 중 하나. 지금은 O에만 작동한다.\n",
    "    :param data: 원소는 cat에 속하는 글자 하나로만 이루어져 있어야 한다.\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    tensor = tf.ragged.constant(data)\n",
    "    vector = tf.reshape(tensor, [-1])\n",
    "    len_vector = tf.size(vector)\n",
    "    count = tf.reduce_sum(tf.cast(tf.equal(cat, vector), tf.int32))\n",
    "    return count / len_vector\n",
    "\n",
    "\n",
    "count_O = rate_category('O', bios_all_sentences)\n",
    "\n",
    "# rate_O = count_O / count_all\n",
    "print(f\"num('O')/num('BIO') = {count_O:3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# if given, it will be added to word_index and used to replace out-of-vocabulary\n",
    "# words during text_to_sequence calls\n",
    "token_tokenizer = keras.preprocessing.text.Tokenizer(oov_token=\"OOV\")\n",
    "token_tokenizer.fit_on_texts(tokens_all_sentences)\n",
    "\n",
    "bio_tokenizer = keras.preprocessing.text.Tokenizer(lower=False)  # 토큰은 그대로 둔다.\n",
    "bio_tokenizer.fit_on_texts(bios_all_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 모델 추론 결과를 다시 읽을 수 있는 형태로 되돌리기 위해 매핑 저장.\n",
    "token_index_word = token_tokenizer.index_word\n",
    "tag_index_word = bio_tokenizer.index_word\n",
    "tag_index_word[0] = 'PAD'  # `0` is a reserved index that won't be assigned to any word.\n",
    "\n",
    "token_space_size = len(token_index_word) + 1\n",
    "bio_space_size = len(tag_index_word) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset_x = token_tokenizer.texts_to_sequences(tokens_all_sentences)\n",
    "dataset_y = bio_tokenizer.texts_to_sequences(bios_all_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 이 길이로 시퀀스를 고정하고, 임베딩 레이어의 `input_length` 인자로 준다.\n",
    "maxlen = max(map(lambda token_sequence: len(token_sequence), dataset_x))\n",
    "padded_dataset_x = keras.preprocessing.sequence.pad_sequences(\n",
    "    dataset_x,\n",
    "    maxlen=maxlen,  # maxlen 주어지지 않으면 자동으로 최장 시퀀스 길이를 따름.\n",
    "    padding=\"post\")\n",
    "padded_dataset_y = keras.preprocessing.sequence.pad_sequences(\n",
    "    dataset_y,\n",
    "    maxlen=maxlen,\n",
    "    padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(\n",
    "    padded_dataset_x,\n",
    "    padded_dataset_y,\n",
    "    test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "one_hot_train_y = tf.keras.utils.to_categorical(train_y, num_classes=bio_space_size)\n",
    "one_hot_test_y = tf.keras.utils.to_categorical(test_y, num_classes=token_space_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(2844, 168, 8)"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2844, 168)\n",
      "(2844, 168, 8)\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape)  # len_dataset, len_sequence\n",
    "print(one_hot_train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainset = tf.data.Dataset.from_tensor_slices((train_x, one_hot_train_y)).batch(128)\n",
    "testset = tf.data.Dataset.from_tensor_slices((test_x, one_hot_test_y)).batch(128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 모델 빌드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "bi_lstm_model_dir = \"models/bi_lstm_for_ner\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_layer = keras.layers.Input(shape=[maxlen, ])\n",
    "embedding_layer_fn = keras.layers.Embedding(\n",
    "    input_dim=token_space_size,\n",
    "    output_dim=30,\n",
    "    mask_zero=True,  # 시퀀스를 0으로 패딩했다면 True로 값을 설정해 그 0이 패딩임을 고지.\n",
    "    input_length=maxlen)  # Length of input sequences\n",
    "bi_lstm_layer_fn = keras.layers.Bidirectional(\n",
    "    tf.keras.layers.LSTM(\n",
    "        200,  # 레이어 내 노드 수.\n",
    "        return_sequences=True,  # 정방향과 역방향 출력을 하나의 시퀀스로 묶는다.\n",
    "        dropout=.5,\n",
    "        # T면 [timesteps, batch, feature] F면 [batch, timesteps, feature]의 입력\n",
    "        # 형상으로 True일 떄가 연산 효율은 더 좋다(기본값 False).\n",
    "        # time_major= True\n",
    "        recurrent_dropout=.25))\n",
    "# '어느 개체명이 가장 가능성 높은가?'를 마지막 밀집층으로 보여준다.\n",
    "dense_layer_fn = keras.layers.TimeDistributed(\n",
    "    keras.layers.Dense(bio_space_size, activation=\"softmax\"))\n",
    "\n",
    "embedding_layer = embedding_layer_fn(input_layer)\n",
    "bi_lstm_layer = bi_lstm_layer_fn(embedding_layer)\n",
    "dense_layer = dense_layer_fn(bi_lstm_layer)\n",
    "\n",
    "bi_lstm_model = keras.Model(inputs=input_layer, outputs=dense_layer)\n",
    "bi_lstm_model.compile(loss=\"categorical_crossentropy\",\n",
    "                      optimizer=\"adam\",\n",
    "                      metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "23/23 [==============================] - 41s 2s/step - loss: 0.2412 - accuracy: 0.8261\n",
      "Epoch 2/1000\n",
      "23/23 [==============================] - 48s 2s/step - loss: 0.1303 - accuracy: 0.8572\n",
      "Epoch 3/1000\n",
      "23/23 [==============================] - 52s 2s/step - loss: 0.1243 - accuracy: 0.8572\n",
      "Epoch 4/1000\n",
      "23/23 [==============================] - 53s 2s/step - loss: 0.1190 - accuracy: 0.8572\n",
      "Epoch 5/1000\n",
      "23/23 [==============================] - 55s 2s/step - loss: 0.1114 - accuracy: 0.8566\n",
      "Epoch 6/1000\n",
      "23/23 [==============================] - 57s 2s/step - loss: 0.0958 - accuracy: 0.8635\n",
      "Epoch 7/1000\n",
      "23/23 [==============================] - 58s 3s/step - loss: 0.0800 - accuracy: 0.8770\n",
      "Epoch 8/1000\n",
      "23/23 [==============================] - 60s 3s/step - loss: 0.0694 - accuracy: 0.8856\n",
      "Epoch 9/1000\n",
      "23/23 [==============================] - 60s 3s/step - loss: 0.0631 - accuracy: 0.8921\n",
      "Epoch 10/1000\n",
      "23/23 [==============================] - 60s 3s/step - loss: 0.0590 - accuracy: 0.8991\n",
      "Epoch 11/1000\n",
      "23/23 [==============================] - 60s 3s/step - loss: 0.0558 - accuracy: 0.9042\n",
      "Epoch 12/1000\n",
      "23/23 [==============================] - 62s 3s/step - loss: 0.0537 - accuracy: 0.9087\n",
      "Epoch 13/1000\n",
      "23/23 [==============================] - 63s 3s/step - loss: 0.0522 - accuracy: 0.9122\n",
      "Epoch 14/1000\n",
      "23/23 [==============================] - 63s 3s/step - loss: 0.0520 - accuracy: 0.9130\n",
      "Epoch 15/1000\n",
      "23/23 [==============================] - 62s 3s/step - loss: 0.0494 - accuracy: 0.9182\n",
      "Epoch 16/1000\n",
      "23/23 [==============================] - 63s 3s/step - loss: 0.0469 - accuracy: 0.9224\n",
      "Epoch 17/1000\n",
      "23/23 [==============================] - 64s 3s/step - loss: 0.0447 - accuracy: 0.9256\n",
      "Epoch 18/1000\n",
      "23/23 [==============================] - 64s 3s/step - loss: 0.0425 - accuracy: 0.9293\n",
      "Epoch 19/1000\n",
      "23/23 [==============================] - 64s 3s/step - loss: 0.0402 - accuracy: 0.9335\n",
      "Epoch 20/1000\n",
      "23/23 [==============================] - 64s 3s/step - loss: 0.0377 - accuracy: 0.9378\n",
      "Epoch 21/1000\n",
      "23/23 [==============================] - 64s 3s/step - loss: 0.0355 - accuracy: 0.9424\n",
      "Epoch 22/1000\n",
      "23/23 [==============================] - 64s 3s/step - loss: 0.0336 - accuracy: 0.9467\n",
      "Epoch 23/1000\n",
      "23/23 [==============================] - 63s 3s/step - loss: 0.0313 - accuracy: 0.9500\n",
      "Epoch 24/1000\n",
      "23/23 [==============================] - 64s 3s/step - loss: 0.0297 - accuracy: 0.9534\n",
      "Epoch 25/1000\n",
      "23/23 [==============================] - 64s 3s/step - loss: 0.0288 - accuracy: 0.9548\n",
      "Epoch 26/1000\n",
      "23/23 [==============================] - 64s 3s/step - loss: 0.0285 - accuracy: 0.9557\n",
      "Epoch 27/1000\n",
      "23/23 [==============================] - 65s 3s/step - loss: 0.0275 - accuracy: 0.9574\n",
      "Epoch 28/1000\n",
      "23/23 [==============================] - 65s 3s/step - loss: 0.0237 - accuracy: 0.9647\n",
      "Epoch 29/1000\n",
      "23/23 [==============================] - 66s 3s/step - loss: 0.0218 - accuracy: 0.9685\n",
      "Epoch 30/1000\n",
      "23/23 [==============================] - 65s 3s/step - loss: 0.0198 - accuracy: 0.9713\n",
      "Epoch 31/1000\n",
      "23/23 [==============================] - 65s 3s/step - loss: 0.0183 - accuracy: 0.9742\n",
      "Epoch 32/1000\n",
      "23/23 [==============================] - 64s 3s/step - loss: 0.0166 - accuracy: 0.9764\n",
      "Epoch 33/1000\n",
      "23/23 [==============================] - 65s 3s/step - loss: 0.0158 - accuracy: 0.9781\n",
      "Epoch 34/1000\n",
      "23/23 [==============================] - 65s 3s/step - loss: 0.0149 - accuracy: 0.9788\n",
      "Epoch 35/1000\n",
      "23/23 [==============================] - 64s 3s/step - loss: 0.0145 - accuracy: 0.9794\n",
      "Epoch 36/1000\n",
      "23/23 [==============================] - 64s 3s/step - loss: 0.0156 - accuracy: 0.9768\n",
      "Epoch 37/1000\n",
      "23/23 [==============================] - 64s 3s/step - loss: 0.0150 - accuracy: 0.9774\n",
      "Epoch 38/1000\n",
      "23/23 [==============================] - 65s 3s/step - loss: 0.0141 - accuracy: 0.9792\n",
      "Epoch 39/1000\n",
      "23/23 [==============================] - 64s 3s/step - loss: 0.0140 - accuracy: 0.9791\n",
      "Epoch 40/1000\n",
      "23/23 [==============================] - 64s 3s/step - loss: 0.0137 - accuracy: 0.9791\n",
      "Epoch 41/1000\n",
      "23/23 [==============================] - 64s 3s/step - loss: 0.0115 - accuracy: 0.9828\n",
      "Epoch 42/1000\n",
      "23/23 [==============================] - 65s 3s/step - loss: 0.0098 - accuracy: 0.9862\n",
      "Epoch 43/1000\n",
      "23/23 [==============================] - 65s 3s/step - loss: 0.0092 - accuracy: 0.9868\n",
      "Epoch 44/1000\n",
      "23/23 [==============================] - 64s 3s/step - loss: 0.0087 - accuracy: 0.9875\n",
      "Epoch 45/1000\n",
      "23/23 [==============================] - 64s 3s/step - loss: 0.0082 - accuracy: 0.9883\n",
      "Epoch 46/1000\n",
      "23/23 [==============================] - 65s 3s/step - loss: 0.0080 - accuracy: 0.9884\n",
      "Epoch 47/1000\n",
      "23/23 [==============================] - 65s 3s/step - loss: 0.0076 - accuracy: 0.9889\n",
      "Epoch 48/1000\n",
      "23/23 [==============================] - 65s 3s/step - loss: 0.0073 - accuracy: 0.9896\n",
      "Epoch 49/1000\n",
      "23/23 [==============================] - 65s 3s/step - loss: 0.0071 - accuracy: 0.9899\n",
      "Epoch 50/1000\n",
      "23/23 [==============================] - 65s 3s/step - loss: 0.0067 - accuracy: 0.9906\n",
      "Epoch 51/1000\n",
      "23/23 [==============================] - 65s 3s/step - loss: 0.0065 - accuracy: 0.9903\n",
      "Epoch 52/1000\n",
      "23/23 [==============================] - 66s 3s/step - loss: 0.0063 - accuracy: 0.9911\n",
      "Epoch 53/1000\n",
      "23/23 [==============================] - 65s 3s/step - loss: 0.0062 - accuracy: 0.9910\n",
      "Epoch 54/1000\n",
      "23/23 [==============================] - 65s 3s/step - loss: 0.0057 - accuracy: 0.9918\n",
      "Epoch 55/1000\n",
      "23/23 [==============================] - 66s 3s/step - loss: 0.0057 - accuracy: 0.9912\n",
      "Epoch 56/1000\n",
      "23/23 [==============================] - 67s 3s/step - loss: 0.0057 - accuracy: 0.9918\n",
      "Epoch 57/1000\n",
      "23/23 [==============================] - 66s 3s/step - loss: 0.0053 - accuracy: 0.9918\n",
      "Epoch 58/1000\n",
      "23/23 [==============================] - 67s 3s/step - loss: 0.0052 - accuracy: 0.9924\n",
      "Epoch 59/1000\n",
      "23/23 [==============================] - 67s 3s/step - loss: 0.0051 - accuracy: 0.9924\n",
      "Epoch 60/1000\n",
      "23/23 [==============================] - 66s 3s/step - loss: 0.0051 - accuracy: 0.9926\n",
      "Epoch 61/1000\n",
      "23/23 [==============================] - 66s 3s/step - loss: 0.0055 - accuracy: 0.9917\n",
      "Epoch 62/1000\n",
      "23/23 [==============================] - 66s 3s/step - loss: 0.0058 - accuracy: 0.9909\n",
      "Epoch 63/1000\n",
      "23/23 [==============================] - 65s 3s/step - loss: 0.0069 - accuracy: 0.9887\n",
      "Epoch 64/1000\n",
      "23/23 [==============================] - 64s 3s/step - loss: 0.0065 - accuracy: 0.9895\n"
     ]
    }
   ],
   "source": [
    "# 오래 걸려서 GPU 달린 서버에서 실행(레거시 옵티마이저가 아님에 주의!)\n",
    "bi_lstm_history = bi_lstm_model.fit(trainset,  # train_x, one_hot_train_y,\n",
    "                                    epochs=1000,\n",
    "                                    callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/bi_lstm_for_ner\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002AC91F0D760> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002AC91F162E0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "bi_lstm_model.save(bi_lstm_model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 입력 형상 생각하기 귀찮으면..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "another_model = keras.Sequential()\n",
    "\n",
    "another_model.add(embedding_layer_fn)\n",
    "another_model.add(bi_lstm_layer_fn)\n",
    "another_model.add(dense_layer_fn)\n",
    "another_model.compile(loss=\"categorical_crossentropy\",\n",
    "                      optimizer=keras.optimizers.legacy.Adam(),\n",
    "                      metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-18 18:19:46.985958: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[32], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43manother_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_x\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      2\u001B[0m \u001B[43m                  \u001B[49m\u001B[43mone_hot_train_y\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m                  \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m128\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m                  \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1000\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[43m                  \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mearly_stopping\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/chatbot/venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/PycharmProjects/chatbot/venv/lib/python3.8/site-packages/keras/engine/training.py:1650\u001B[0m, in \u001B[0;36mModel.fit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1642\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[1;32m   1643\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   1644\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1647\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[1;32m   1648\u001B[0m ):\n\u001B[1;32m   1649\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[0;32m-> 1650\u001B[0m     tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1651\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[1;32m   1652\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[0;32m~/PycharmProjects/chatbot/venv/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/PycharmProjects/chatbot/venv/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:880\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    877\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    879\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[0;32m--> 880\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    882\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[1;32m    883\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[0;32m~/PycharmProjects/chatbot/venv/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:945\u001B[0m, in \u001B[0;36mFunction._call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    941\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m  \u001B[38;5;66;03m# Fall through to cond-based initialization.\u001B[39;00m\n\u001B[1;32m    942\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    943\u001B[0m     \u001B[38;5;66;03m# Lifting succeeded, so variables are initialized and we can run the\u001B[39;00m\n\u001B[1;32m    944\u001B[0m     \u001B[38;5;66;03m# no_variable_creation function.\u001B[39;00m\n\u001B[0;32m--> 945\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_no_variable_creation_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    946\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    947\u001B[0m   _, _, filtered_flat_args \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    948\u001B[0m       \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_variable_creation_fn\u001B[38;5;241m.\u001B[39m_function_spec  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[1;32m    949\u001B[0m       \u001B[38;5;241m.\u001B[39mcanonicalize_function_inputs(\n\u001B[1;32m    950\u001B[0m           args, kwds))\n",
      "File \u001B[0;32m~/PycharmProjects/chatbot/venv/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:134\u001B[0m, in \u001B[0;36mTracingCompiler.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    131\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[1;32m    132\u001B[0m   (concrete_function,\n\u001B[1;32m    133\u001B[0m    filtered_flat_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_define_function(args, kwargs)\n\u001B[0;32m--> 134\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mconcrete_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    135\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfiltered_flat_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconcrete_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/chatbot/venv/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1745\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[0;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[1;32m   1741\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[1;32m   1742\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[1;32m   1743\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[1;32m   1744\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[0;32m-> 1745\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_call_outputs(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1746\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcancellation_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcancellation_manager\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m   1747\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[1;32m   1748\u001B[0m     args,\n\u001B[1;32m   1749\u001B[0m     possible_gradient_type,\n\u001B[1;32m   1750\u001B[0m     executing_eagerly)\n\u001B[1;32m   1751\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[0;32m~/PycharmProjects/chatbot/venv/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:378\u001B[0m, in \u001B[0;36m_EagerDefinedFunction.call\u001B[0;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[1;32m    376\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _InterpolateFunctionError(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    377\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m cancellation_manager \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 378\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    379\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msignature\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    380\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_num_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    381\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    382\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    383\u001B[0m \u001B[43m        \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mctx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    384\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    385\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[1;32m    386\u001B[0m         \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msignature\u001B[38;5;241m.\u001B[39mname),\n\u001B[1;32m    387\u001B[0m         num_outputs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_outputs,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    390\u001B[0m         ctx\u001B[38;5;241m=\u001B[39mctx,\n\u001B[1;32m    391\u001B[0m         cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_manager)\n",
      "File \u001B[0;32m~/PycharmProjects/chatbot/venv/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:52\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     50\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     51\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[0;32m---> 52\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     53\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     54\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     55\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "another_model.fit(train_x,\n",
    "                  one_hot_train_y,\n",
    "                  batch_size=128,\n",
    "                  epochs=1000,\n",
    "                  callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 테스트셋으로 성능 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-18 21:25:43.065099: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-01-18 21:25:43.065119: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "loaded_model = tf.saved_model.load(bi_lstm_model_dir)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_fn = loaded_model.signatures[\"serving_default\"]\n",
    "test_x = test_x.astype(np.float32)  # 기본 타입 float32인 거 모델 빌드 때 까먹었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "pred_y = pred_fn(input_3=test_x)  # 서명 잘못 설정했다..."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 임베딩된 상태라 그대로 읽기 어려우니 앞서 선언했던 `token_index_word`, `tag_index_word` 활용.\n",
    "pred_y = pred_y[\"time_distributed_2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sequences_to_tag(sequences, mapping_dict):\n",
    "    \"\"\"\"one-hot 결과를 읽을 수 있는 문자로 변환한다.\n",
    "\n",
    "    각 시퀀스는 토큰별 one-hot 추론 결과를 원소로 담고 있다. [num_seq, len_seq, len_one_hot]\n",
    "\n",
    "    :param sequences: 추론된 원-핫 형식 태그 콜렉션. 추론 함수의 결과 텐서를 기대한다.\n",
    "    :param mapping_dict: 인코딩된 태그값에 해당하는 원래 문자 태그의 매핑.\n",
    "    :return: `mapping_dict`에 의해 문자로 변환된 시퀀스들.\n",
    "    \"\"\"\n",
    "    tags_all_sequences = []\n",
    "    for sequence in sequences:\n",
    "        tags_a_sequence = []\n",
    "        for one_hot_score in sequence:\n",
    "            most_likely_index = np.argmax(one_hot_score)\n",
    "            pred_tag = mapping_dict[most_likely_index].replace(\"PAD\", \"O\")\n",
    "            tags_a_sequence.append(pred_tag)\n",
    "        tags_all_sequences.append(tags_a_sequence)\n",
    "\n",
    "    return tags_all_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "data": {
      "text/plain": "TensorShape([711, 168, 8])"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_y.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 시간이 걸리므로 pickle 직렬화 보존하자.\n",
    "decoded_pred_tags = sequences_to_tag(pred_y, tag_index_word)\n",
    "decoded_test_tags = sequences_to_tag(test_y, tag_index_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "with open(\"data/corpus/korean_ner/decoded_pred_tags.pickle\", \"wb\") as fout:\n",
    "     pickle.dump(decoded_pred_tags, fout)\n",
    "\n",
    "with open(\"data/corpus/korean_ner/decoded_test_tags\", \"wb\") as fout:\n",
    "    pickle.dump(decoded_test_tags, fout)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakjun/PycharmProjects/chatbot/venv/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_PS seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/Users/hakjun/PycharmProjects/chatbot/venv/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_DT seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/Users/hakjun/PycharmProjects/chatbot/venv/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_OG seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/Users/hakjun/PycharmProjects/chatbot/venv/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_LC seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/Users/hakjun/PycharmProjects/chatbot/venv/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_TI seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/Users/hakjun/PycharmProjects/chatbot/venv/lib/python3.8/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/hakjun/PycharmProjects/chatbot/venv/lib/python3.8/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(decoded_test_tags, decoded_pred_tags)\n",
    "f1 = f1_score(decoded_test_tags, decoded_pred_tags)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           _       0.00      0.00      0.00         0\n",
      "         _DT       0.00      0.00      0.00         0\n",
      "         _LC       0.00      0.00      0.00         0\n",
      "         _OG       0.00      0.00      0.00         0\n",
      "         _PS       0.00      0.00      0.00         0\n",
      "         _TI       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.00      0.00      0.00         0\n",
      "   macro avg       0.00      0.00      0.00         0\n",
      "weighted avg       0.00      0.00      0.00         0\n",
      "\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(report)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "data": {
      "text/plain": "157"
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([p == a for p, a in zip(decoded_pred_tags[0], decoded_test_tags[0])])"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.16 ('tensorflow_gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "72a30fb20ccb3b5f1323604f7dc65936ec8219365d815ccd0e4ed70e4e4b4b7c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
