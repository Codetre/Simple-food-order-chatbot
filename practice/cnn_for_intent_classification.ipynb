{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 191,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import preprocessing as preprocessing\n",
    "# optimizer 문제: https://developer.apple.com/forums/thread/721735\n",
    "from tensorflow.keras.optimizers.legacy import Adam"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CNN 기본 설명\n",
    "합성곱(convolution): 데이터 위를 필터(윈도우, 커널, 마스크 등 다양하게 불림)가 지정된 스트라이드씩\n",
    "슬라이딩하며 필터가 나타내는 특징을 추출한다. 마지막 위치까지 슬라이딩을 마치면 찾고자\n",
    "했던 특징이 데이터 전체에서 나타난 '특징맵(feature map)'이 출력되는 연산이다.\n",
    "\n",
    "풀링(pooling): 합성곱과 마찬가지로 윈도우가 있으며 데이터 위를 슬라이딩한단 점은 동일하다. 차이점은\n",
    "슬라이딩마다 윈도우 범위 내에서 가장 특징이 뚜렷한 지점의 값을 찾거나, 윈도우 범위 내 특징의 평균값을\n",
    "낸다는 점이다. 전자를 최대 풀링(max pooling), 후자를 평균 풀링(average pooling) 연산이라고 부른다.\n",
    "\n",
    "합성곱으로 피처맵 추출 -> 피처맵에서 최대 풀링 연산으로 가장 뚜렷한 특징값을 집약 순서로 레이어를 구성한다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 데이터와 모델 설명\n",
    "데이터(인공): [Chatbot_data_for_Korean v1.0](https://github.com/songys/Chatbot_data)\n",
    "필드: Q(사용자 입력), A(가상의 챗봇 반응), label(감정, 0: 일상적, 1: 이별, 2: 사랑)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "outputs": [],
   "source": [
    "def features_and_labels(csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    features, labels = df[\"Q\"].tolist(), df[\"label\"].tolist()\n",
    "    return features, labels\n",
    "\n",
    "\n",
    "def dataset_and_metadata(features, labels, batch_size=20):\n",
    "    \"\"\"데이터셋과 그에 관해 설명하는 메타데이터.\n",
    "\n",
    "    :param features: `features_and_labels`의 첫번째 리턴.\n",
    "    :param labels: `features_and_labels`의 두번째 리턴.\n",
    "    :return: 데이터셋과 그에 관한 메타데이터. 메타데이터는 프로그램 중간중간 필요하기에 뽑았다.\n",
    "    \"\"\"\n",
    "    # `text_to_word_sequence` 메소드로 텍스트를 토큰 단위로 나눈 단어 시퀀스 생성.\n",
    "    tokens = [preprocessing.text.text_to_word_sequence(document)\n",
    "              for document in features]\n",
    "\n",
    "    tokenizer = preprocessing.text.Tokenizer()\n",
    "    tokenizer.fit_on_texts(tokens)\n",
    "    # 각 문서 내 토큰을 숫자로 치환. `texts_to_sequences`는 `fit_on_texts` 메서드에 인자로 준\n",
    "    # 토큰만 인식할 수 있다. 빈도가 높은 순으로 (num_words - 1)개의 단어만 고려한다.\n",
    "    int_sequences = tokenizer.texts_to_sequences(tokens)\n",
    "    index_word = tokenizer.index_word  # 토큰에 어떤 번호를 부여했는지 매핑 객체.\n",
    "\n",
    "    # CNN 모델은 고정 크기 벡터를 요구한다. 고정 크기 설정 시 벡터의 길이보다 짧게 잡으면 정보 손실이\n",
    "    # 일어나므로 문서들에서 가장 긴 벡터의 길이를 알아야 한다.\n",
    "    lens_sequences = list(map(lambda vector: len(vector), int_sequences))\n",
    "    fixed_len_sequence = 15  # 테스트셋까지 고려하면 15가 최소 길이. max(lens_sequences)\n",
    "    padded_int_sequences = preprocessing.sequence.pad_sequences(\n",
    "        int_sequences,\n",
    "        maxlen=fixed_len_sequence,\n",
    "        padding=\"post\")  # 벡터 뒤에 패딩을 붙인다. 기본은 'pre'.\n",
    "\n",
    "    # 인자로 받은 텐서들을 잘라내(slice) 데이터셋을 만든다. 여기선 파이썬의 `zip`함수를 생각하면 된다.\n",
    "    # `zip(features, labels)`은 각 순회마다 `(feature[i], labels[i])를 출력한다.\n",
    "    # 이와 마찬가지로 `from_tensor_slices`도 `(feat, lbl)`로 묶인 TensorSliceDataset을 리턴.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((padded_int_sequences, labels))\n",
    "    dataset.shuffle(len(padded_int_sequences))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "\n",
    "    metadata = {\n",
    "        \"vocab_size\": len(index_word) + 1,  # 데이터셋 내 모든 구별되는 단어 개수.\n",
    "        \"fixed_len_sequence\": fixed_len_sequence}\n",
    "\n",
    "    return dataset, metadata"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "outputs": [],
   "source": [
    "# 데이터셋 생성\n",
    "data_dir = \"data/corpus/chatbot_data\"\n",
    "train_file = os.path.join(data_dir, \"trainset.csv\")\n",
    "test_file = os.path.join(data_dir, \"testset.csv\")\n",
    "\n",
    "train_features, train_labels = features_and_labels(train_file)\n",
    "test_features, test_labels = features_and_labels(test_file)\n",
    "\n",
    "batch_size = 20\n",
    "trainset, train_metadata = dataset_and_metadata(\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    batch_size)\n",
    "testset, test_metadata = dataset_and_metadata(\n",
    "    test_features,\n",
    "    test_labels,\n",
    "    batch_size)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset element_spec=(TensorSpec(shape=(None, 15), dtype=tf.int32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>\n"
     ]
    }
   ],
   "source": [
    "print(trainset)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "outputs": [],
   "source": [
    "# 모델 하이퍼파라미터 설정\n",
    "dropout_prob = 0.5\n",
    "emb_size = 128  # 임베딩 벡터 크기.\n",
    "epoch = 5\n",
    "eval_split = 0.7\n",
    "# `texts_to_sequences`는 top(num_words - 1)만 고려하는 특성이 있어서 1을 더해야 한다.\n",
    "logit_space_size = len(set(train_labels))  # 분류할 감정은 0, 1, 2 세 가지다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "outputs": [],
   "source": [
    "input_layer = tf.keras.layers.Input(shape=(train_metadata[\"fixed_len_sequence\"],))\n",
    "embedding_layer = tf.keras.layers.Embedding(\n",
    "    input_dim=train_metadata[\"vocab_size\"],\n",
    "    output_dim=emb_size,\n",
    "    input_length=train_metadata[\"fixed_len_sequence\"])(input_layer)\n",
    "dropout_emb_layer = tf.keras.layers.Dropout(rate=dropout_prob)(embedding_layer)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "outputs": [],
   "source": [
    "conv_layer1 = tf.keras.layers.Conv1D(\n",
    "    filters=emb_size,  # Integer, the dimensionality of the output space\n",
    "    kernel_size=3,  # 길이 3인 벡터로 n-gram의 n과 같은 역할을 수행.\n",
    "    padding=\"valid\",  # 패딩 없음.\n",
    "    activation=tf.nn.relu,\n",
    "    name=\"conv1\")(dropout_emb_layer)\n",
    "pooling_layer1 = tf.keras.layers.GlobalMaxPool1D()(conv_layer1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "outputs": [],
   "source": [
    "conv_layer2 = tf.keras.layers.Conv1D(\n",
    "    filters=emb_size,\n",
    "    kernel_size=4,\n",
    "    padding=\"valid\",\n",
    "    activation=tf.nn.relu,\n",
    "    name=\"conv2\")(dropout_emb_layer)\n",
    "pooling_layer2 = tf.keras.layers.GlobalMaxPool1D()(conv_layer2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "outputs": [],
   "source": [
    "conv_layer3 = tf.keras.layers.Conv1D(\n",
    "    filters=emb_size,\n",
    "    kernel_size=5,  # n-gram 크기를 키우면서 넓은 문맥의 의미도 추출한다.\n",
    "    padding=\"valid\",\n",
    "    activation=tf.nn.relu,\n",
    "    name=\"conv3\")(dropout_emb_layer)\n",
    "pooling_layer3 = tf.keras.layers.GlobalMaxPool1D()(conv_layer3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "outputs": [],
   "source": [
    "pooling_layer_sequence = [pooling_layer1, pooling_layer2, pooling_layer3]\n",
    "concat = tf.keras.layers.concatenate(pooling_layer_sequence)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "outputs": [],
   "source": [
    "dense_layer = tf.keras.layers.Dense(\n",
    "    units=emb_size,\n",
    "    activation=tf.nn.relu)(concat)\n",
    "dropout_dense_layer = tf.keras.layers.Dropout(rate=dropout_prob)(dense_layer)\n",
    "logit_layer = tf.keras.layers.Dense(\n",
    "    units=logit_space_size,\n",
    "    name=\"logits\")(dropout_dense_layer)\n",
    "prediction_layer = tf.keras.layers.Dense(\n",
    "    units=logit_space_size,\n",
    "    activation=tf.nn.softmax)(logit_layer)  # 엔트로피 함수로 학습하기 위해선 출력이 확률이어야 한다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "outputs": [],
   "source": [
    "model = tf.keras.Model(inputs=input_layer, outputs=prediction_layer)\n",
    "model.compile(\n",
    "    optimizer=Adam(),  # \"adam\" 대신. tensorflow-macos 2.11에서 호환성 문제가 있다.\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_20\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_9 (InputLayer)           [(None, 15)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding_8 (Embedding)        (None, 15, 128)      1440000     ['input_9[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_19 (Dropout)           (None, 15, 128)      0           ['embedding_8[0][0]']            \n",
      "                                                                                                  \n",
      " conv1 (Conv1D)                 (None, 13, 128)      49280       ['dropout_19[0][0]']             \n",
      "                                                                                                  \n",
      " conv2 (Conv1D)                 (None, 12, 128)      65664       ['dropout_19[0][0]']             \n",
      "                                                                                                  \n",
      " conv3 (Conv1D)                 (None, 11, 128)      82048       ['dropout_19[0][0]']             \n",
      "                                                                                                  \n",
      " global_max_pooling1d_29 (Globa  (None, 128)         0           ['conv1[0][0]']                  \n",
      " lMaxPooling1D)                                                                                   \n",
      "                                                                                                  \n",
      " global_max_pooling1d_30 (Globa  (None, 128)         0           ['conv2[0][0]']                  \n",
      " lMaxPooling1D)                                                                                   \n",
      "                                                                                                  \n",
      " global_max_pooling1d_31 (Globa  (None, 128)         0           ['conv3[0][0]']                  \n",
      " lMaxPooling1D)                                                                                   \n",
      "                                                                                                  \n",
      " concatenate_9 (Concatenate)    (None, 384)          0           ['global_max_pooling1d_29[0][0]',\n",
      "                                                                  'global_max_pooling1d_30[0][0]',\n",
      "                                                                  'global_max_pooling1d_31[0][0]']\n",
      "                                                                                                  \n",
      " dense_21 (Dense)               (None, 128)          49280       ['concatenate_9[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_20 (Dropout)           (None, 128)          0           ['dense_21[0][0]']               \n",
      "                                                                                                  \n",
      " logits (Dense)                 (None, 3)            387         ['dropout_20[0][0]']             \n",
      "                                                                                                  \n",
      " dense_22 (Dense)               (None, 3)            12          ['logits[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,686,671\n",
      "Trainable params: 1,686,671\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-17 04:24:14.734924: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "473/473 [==============================] - 8s 16ms/step - loss: 0.3888 - accuracy: 0.9401\n",
      "Epoch 2/5\n",
      "473/473 [==============================] - 7s 15ms/step - loss: 0.5998 - accuracy: 0.8383\n",
      "Epoch 3/5\n",
      "473/473 [==============================] - 7s 15ms/step - loss: 0.4035 - accuracy: 0.8695\n",
      "Epoch 4/5\n",
      "473/473 [==============================] - 7s 15ms/step - loss: 0.3499 - accuracy: 0.9076\n",
      "Epoch 5/5\n",
      "473/473 [==============================] - 7s 15ms/step - loss: 0.4163 - accuracy: 0.8725\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x29885adf0>"
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trainset, epochs=epoch, verbose=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 14/119 [==>...........................] - ETA: 0s - loss: 0.3146 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-17 04:24:51.147691: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 1s 7ms/step - loss: 0.3334 - accuracy: 0.9992\n",
      "Accuracy: 0.9991543889045715, loss: 0.33344805240631104\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(testset, verbose=1)\n",
    "print(f\"Accuracy: {accuracy}, loss: {loss}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/intent_classifier/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/intent_classifier/assets\n"
     ]
    }
   ],
   "source": [
    "model_save_path = \"models/intent_classifier\"\n",
    "model.save(model_save_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
