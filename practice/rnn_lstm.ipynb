{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# RNN(Recurrent Neural Network)\n",
    "`h_now = f(h_prev, x_now) = tanh(h_prev * w_h + x_now * w_x + b)`\n",
    "`y_now = h_now * w_y + b_y`\n",
    "\n",
    "- one-to-many: RNN 층에는 첫 시점에만 값이 들어오며, 이 값으로 출력 시퀀스를 만든다.\n",
    "    - 이미지를 받아 이를 설명하는 단어 시퀀스를 출력.\n",
    "- many-to-many: RNN 층에 여러 시점에 값이 들어오며, 이 값으로 출력 시퀀스를 만든다.\n",
    "    - 토큰 시퀀스를 받아, 각 토큰의 개체명을 출력.\n",
    "- many-to-one: RNN 층에 여러 시점에 값이 들어오며, 이 값으로 최종 시점에 출력을 만든다.\n",
    "    - 일정 기간 월별 판매량 데이터로 다음 달 판매량 예측.\n",
    "\n",
    "이번 노트북에서는 `x=[-10, 10]` 범위 sin 함수로 학습한 RNN 모델에게, 다른 범위의 x를 주고\n",
    "값을 예측하도록 시킨 다음 이를 그 범위의 cos 함수와 비교한다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 데이터 준비"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def split_seqeunce(sequence, step):\n",
    "    \"\"\"데이터셋용 시퀀스 분할.\n",
    "\n",
    "    x, y = sequence[i:i + step], sequence[i + step]\n",
    "    시퀀스의 일정 부분을 보고 그 다음엔 뭐가 올지 추측하는 모델을 위한 데이터셋 생성 헬퍼 함수.\n",
    "\n",
    "    :param sequence: 분할 대상.\n",
    "    :param step: 분할 크기.\n",
    "    :return: 분할된 부분과 그 다음 원소의 슬라이스들.\n",
    "    \"\"\"\n",
    "    x, y = [], []\n",
    "\n",
    "    for i in range(len(sequence)):\n",
    "        end_idx = i + step\n",
    "        if end_idx > len(sequence) - 1:\n",
    "            break\n",
    "        x.append(sequence[i:end_idx])\n",
    "        y.append(sequence[end_idx])\n",
    "\n",
    "    return np.array(x), np.array(y)\n",
    "\n",
    "\n",
    "def preprocess(dataset: np.ndarray, new_dim_size: int) -> np.ndarray:\n",
    "    \"\"\"RNN 레이어 입력 요구 사항을 맞추기 위한 전처리.\n",
    "\n",
    "    :param dataset: ndim=2의 ndarray\n",
    "    :param new_dim_size: 추가된 차원의 크기.\n",
    "    :return: ndim = (ndim + 1)로 형태가 바뀐 ndarray\n",
    "    \"\"\"\n",
    "    return dataset.reshape(*dataset.shape, new_dim_size)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_ticks = 15  # RNN이 1회 추론에 입력 받게 될 데이터.\n",
    "n_features = 1  # 전처리 단계와 출력층의 크기로서도 써먹는다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x = np.arange(start=-10, stop=10, step=0.1)\n",
    "dataset_y = np.sin(x)\n",
    "dataset_x, dataset_y = split_seqeunce(dataset_y, x_ticks)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(dataset_x.shape)  # shape: (len(x) / x_ticks, x_ticks)\n",
    "print(dataset_y.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# RNN 요구 shape(ndim=3)을 맞추기 위해 차원 추가.\n",
    "dataset_x = preprocess(dataset_x, n_features)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "input_layer = keras.layers.Input(shape=dataset_x.shape[1:])\n",
    "rnn_layer = keras.layers.SimpleRNN(\n",
    "    units=10,\n",
    "    return_sequences=False,\n",
    "    input_shape=(x_ticks, n_features))(input_layer)\n",
    "dense_layer = keras.layers.Dense(n_features)(rnn_layer)\n",
    "rnn_model = keras.Model(inputs=input_layer, outputs=dense_layer)\n",
    "rnn_model.compile(optimizer=keras.optimizers.legacy.Adam(), loss=\"mse\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"loss\",\n",
    "    patience=5,\n",
    "    mode=\"auto\")\n",
    "history = rnn_model.fit(dataset_x, dataset_y, epochs=1000, callbacks=[early_stopping])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 훈련 결과 확인"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"loss\"], label=\"loss\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 테스트셋 검증"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x = np.arange(10, 20, 0.1)\n",
    "y = np.cos(x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_x, test_y = split_seqeunce(y, x_ticks)\n",
    "print(test_x.shape, test_y.shape)\n",
    "# Preprocess\n",
    "test_x = preprocess(test_x, n_features)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pred_y = rnn_model.predict(test_x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# x[:x_ticks] 분만큼은 범위 문제로 테스트셋에선 예측할 수 없으니, 정답과 예측 그래프를 맞추기 위해\n",
    "# 이 부분은 앞에 정답을 끼워넣는다.\n",
    "len_fixed_pred_y = np.append(y[:x_ticks], pred_y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(x, y, label=\"groundtruth\", color=\"blue\")\n",
    "plt.plot(x, len_fixed_pred_y, label=\"predictions\", color=\"orange\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.ylim(-2, 2)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# LSTM 모델 생성 및 예측\n",
    "\n",
    "RNN 모델의 한계로는 시퀀스가 길어질수록 최근의 데이터 영향이 강하고, 시퀀스 앞쪽의 데이터의 영향은 약해지는\n",
    "장기의존성(Long term dependency)이 생긴다는 점이다. 이를 해소하기 위한 모델 구조로 LSTM이 제안됐다.\n",
    "\n",
    "Long-Short Term Model이란 이름에서 알 수 있듯, 단기 상태이던 은닉 상태(hidden state)에\n",
    "장기 상태인 셀 상태(cell state)를 추가하여 RNN 모델의 단점을 해소했다. 이런 셀 상태를 계산하기 위해\n",
    "'입력, 삭제, 출력 게이트'라는 3개의 게이트 모델에 도입했다.\n",
    "\n",
    "LSTM에서 사용되는 활성화 함수는 두 가지다: sigmoid, tanh. 각각의 함수의 범위는 sig가 `[0, 1]`,\n",
    "tanh가 `[-1, 1]`이다. 여기서 sig는 정보를 얼마나 약화시킬지 감쇠도를, tanh는 정보를 단기 상태 범위로\n",
    "스케일을 축소시킨다.\n",
    "\n",
    "  - 입력 게이트(input gate): 장기 상태에 추가할 정보량(수명)을 의미.\n",
    "    - i_cur = sig(x_cur, h_prev)\n",
    "    - g_cur = tanh(x_cur, h_prev)\n",
    "  - 삭제 게이트(forget gate): 장기 상태를 얼마나 잊을지 감쇠도.\n",
    "    - f_cur = sig(x_cur, h_prev)\n",
    "  - 출력 게이트(output gate): 단기 상태를 얼마나 잊을지 감쇠도.\n",
    "    - o_cur = sig(x_cur, h_prev)\n",
    "\n",
    "  - 단기 상태: 이전 시점까지 끌고 온 장기적 정보(c_cur)를 단기적 정보 범위로 바꾼다.\n",
    "    - h_cur = tanh(c_cur) * o_cur\n",
    "  - 장기 상태: 이전 정보에 감쇠도를 적용 후, 이번 시점 정보를 추가한다.\n",
    "    - c_cur = c_prev * f_cur + i_cur * g_cur\n",
    "\n",
    "\n",
    "모델 구조만 RNN 레이어를 LSTM 레이어로 변경하면 된다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lstm_layer = keras.layers.LSTM(\n",
    "    units=10,\n",
    "    return_sequences=False,\n",
    "    input_shape=(x_ticks, n_features))(input_layer)\n",
    "dense_layer = keras.layers.Dense(n_features)(lstm_layer)\n",
    "lstm_model = keras.Model(inputs=input_layer, outputs=dense_layer)\n",
    "lstm_model.compile(optimizer=keras.optimizers.legacy.Adam(), loss=\"mse\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "history = lstm_model.fit(dataset_x, dataset_y, epochs=1000, callbacks=[early_stopping])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pred_y = lstm_model.predict(test_x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len_fixed_pred_y = np.append(y[:x_ticks], pred_y)\n",
    "plt.plot(x, y, label=\"groundtruth\", color=\"blue\")\n",
    "plt.plot(x, len_fixed_pred_y, label=\"predictions\", color=\"orange\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.ylim(-2, 2)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
